{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3H8_G-kzH4SQ"},"outputs":[],"source":["# Install\n","!pip install imutils -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IIt2rWx-H9mO"},"outputs":[],"source":["#Import packages\n","import numpy as np \n","import pandas as pd\n","import os\n","import cv2\n","from skimage import measure\n","from glob import glob\n","import imutils\n","import matplotlib.pyplot as plt\n","\n","from imutils import contours\n","from PIL import Image as Img\n","from IPython.display import Image\n","\n","from joblib import Parallel, delayed\n","from tqdm import tqdm_notebook as tqdm\n","from tqdm.notebook import tqdm\n","from skimage import measure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2nCBK1TRIBPl"},"outputs":[],"source":["# Mount to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TbsPMEWaIFvS"},"outputs":[],"source":["class CFG:\n","\n","    raw_path = '/content/drive/MyDrive/DL-T Cell Segmentatiom/data_for_classification/'\n","    mask_path = '/content/drive/MyDrive/DL-T Cell Segmentatiom/imagej_for_classification/'\n","    imagej_out_path = '/content/drive/MyDrive/DL-T Cell Segmentatiom/imagej_patch_for_classification/'\n","    \n","# if not os.path.exists(CFG.train_out_path):\n","#     os.makedirs(CFG.train_out_path)\n","#if not os.path.exists(CFG.test_out_path):\n","    #os.makedirs(CFG.test_out_path)"]},{"cell_type":"markdown","metadata":{"id":"6w-9rtpvhD46"},"source":["### Raw image multiply mask"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14883,"status":"ok","timestamp":1675694318470,"user":{"displayName":"Phyllis Hu","userId":"10389928402195581363"},"user_tz":300},"id":"97AhaZUNhEfL","outputId":"6d1d1b71-1666-4b43-c42c-3f82c9371442"},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","0\n"]}],"source":["# counts the number of raw and mask images, make sure they have same number of images\n","filenames = glob(os.path.join(CFG.raw_path + '/*.jpg'))\n","print(len(filenames))\n","\n","jnames = glob(os.path.join(CFG.mask_path + '/*.jpg'))\n","print(len(jnames))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hEYVgk2jDWlj"},"outputs":[],"source":["filenames_pre = []\n","jnames_pre = []\n","for i in range(len(filenames)):\n","  filenames_pre.append(filenames[i].split('/')[-1][:-4])\n","\n","for i in range(len(jnames)):\n","  jnames_pre.append(jnames[i].split('/')[-1][:-9])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DWlalL2okbdy"},"outputs":[],"source":["def return_w_hw(h, w, th, tw):\n","  \"\"\"\n","  this function calculates the pixel dimensions need to be paded in height and width\n","  h: height after padding (output size)\n","  w: width after padding (outputs size)\n","  th: height before padding (input size)\n","  tw: width before padding (input size)\n","  \"\"\"\n","  \n","    if h - th < 0:\n","        top = bottom = 0\n","    elif (h-th)%2 == 0:\n","        top = (h-th)/2\n","        bottom = top\n","    else:\n","        top = (h-th)//2\n","        bottom = top + 1\n","\n","\n","    if w - tw < 0:\n","        left = right = 0   \n","    elif (w - tw)%2 == 0:\n","        left = (w - tw)/2\n","        right = left\n","    else:\n","        left = (w - tw)//2\n","        right = left + 1\n","\n","    return int(top), int(bottom), int(left), int(right)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RxoF4Zg_tNzw"},"outputs":[],"source":["# modify this directory according to your data path\n","maskj_dir = '/content/drive/MyDrive/DL-T Cell Segmentatiom/imagej_for_classification/'\n","\n","def create_patches(image_name, outdir, outdirj):\n","  \"\"\"\n","  this function creats patches and stores patch images\n","  the processing is implemented as follows:\n","  1) generate the multiplied images\n","  2) generate the contour for each patch\n","  3) remove contours that are too small (noise) or too large (not single cell)\n","  4) find dimensions needed to be zero-padded for each patch\n","  5) zero padding each selected region to 100*100\n","  6) resize all the patches to 224*224, according to the input size of the pretrained classification model\n","  7) save the patches with name: \"[IMAGE NAME]_p[ID].jpg\"\n","  \"\"\"\n","    counts = 0\n","\n","     \n","    mask_name = maskj_dir + image_name.split('/')[-1][:-4] + '_mask.jpg'\n","    # print(mask_name)\n","    image = cv2.imread(image_name, 0)\n","    # print(image)\n","    maskj = cv2.imread(mask_name, 0)\n","    maskj = np.array(maskj)/255\n","    # print(maskj)\n","    multiplied = np.multiply(image, maskj)\n","    # print(multiplied)\n","    labelsj = measure.label(maskj, background = 0)\n","  \n","    # remember to comment all command to plot figures when parallel processing\n","    # open too many figure windows will cause crash\n","    plt.figure()\n","    plt.imshow(image)\n","    plt.figure()\n","    plt.imshow(multiplied)\n","\n","    mask_mul = np.zeros(image.shape, dtype=\"uint8\")\n","    for label in np.unique(labelsj):\n","        # print(label)\n","        labelMask = np.zeros(image.shape, dtype=\"uint8\")\n","        labelMask[labelsj == label] = 255\n","        numPixels = cv2.countNonZero(labelMask)\n","        # filter out noise and regions that are too large (most probably not single cell if > 3000)\n","        if numPixels > 300 and numPixels < 3000:\n","            mask_mul = cv2.add(mask_mul, labelMask)\n","            counts = counts + 1\n","    # print(counts)\n","    # plt.figure()\n","    # plt.imshow(mask)\n","\n","    bbox_list = []\n","    box_width = []\n","    box_height = []\n","\n","    cnts_j = cv2.findContours(mask_mul.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    cnts_j = imutils.grab_contours(cnts_j)\n","    cnts_j = contours.sort_contours(cnts_j)[0]\n","\n","    # zero padding to 100*100\n","    bb_dim = 100\n","\n","    for (i, c) in enumerate(cnts_j):\n","        (x, y, w, h) = cv2.boundingRect(c)\n","        pad_dim = max(w, h)\n","        bbox_imgj = multiplied[y:y+pad_dim, x:x+pad_dim]\n","        # pad to 100*100\n","        pad_top, pad_bottom, pad_left, pad_right = return_w_hw(bb_dim, bb_dim, pad_dim, pad_dim)\n","        bbox_imgj = np.pad(bbox_imgj, [(pad_top, pad_bottom), (pad_left, pad_right)], constant_values=0)\n","        # resize to 224*224\n","        bbox_imgj = cv2.resize(bbox_imgj, (224,224))\n","        \n","        plt.figure()\n","        plt.imshow(bbox_img_pad)\n","        # print(bbox_img_pad.shape)\n","        # display(Img.fromarray((bbox_imgj).astype(np.uint8)))\n","        cv2.imwrite(outdirj + image_name.split('/')[-1][:-4] + '_p'+ str(i) + '.jpg', bbox_imgj)\n","  \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":14215,"status":"ok","timestamp":1675696396570,"user":{"displayName":"Phyllis Hu","userId":"10389928402195581363"},"user_tz":300},"id":"gnowP2TFKwJF","outputId":"6b433444-ab6f-4f26-e945-5c9bb7b29c52"},"outputs":[{"ename":"IndexError","evalue":"list index out of range","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m create_patches(\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m, CFG\u001b[38;5;241m.\u001b[39mraw_out_path, CFG\u001b[38;5;241m.\u001b[39mimagej_out_path)\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}],"source":["# you can test the function using a single image\n","# plot the figures you want to see the difference before and after multiply the imageJ mask; and the patches generated\n","create_patches(filenames[10], CFG.raw_out_path, CFG.imagej_out_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TBkOIZ8lnFNf"},"outputs":[],"source":["# parallel processing\n","# modify the [filenames] and [total] if needed\n","res2 = Parallel(n_jobs=16, backend='threading')(delayed(\n","    create_patches)(i, CFG.raw_out_path, CFG.imagej_out_path) for i in tqdm(filenames, total=len(filenames)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78018,"status":"ok","timestamp":1673629645524,"user":{"displayName":"Shiqi Hu","userId":"01032087330787268891"},"user_tz":300},"id":"MVLpkaKouJkT","outputId":"bd8ea0df-5e07-4c9b-f89f-fe954846650d"},"outputs":[{"name":"stdout","output_type":"stream","text":["10055\n","8855\n"]}],"source":["# check the number of output patches to see if processing was successful\n","j_patch = glob(os.path.join(CFG.imagej_out_path + '/*.jpg'))\n","print(len(j_patch))"]}],"metadata":{"colab":{"provenance":[{"file_id":"1_N1Ru3oTqv1ixvY1DNXU7T695Fcgg6yj","timestamp":1667613518340},{"file_id":"1qHMG59sbYns8tZSeudVYwe8CNPkvFmms","timestamp":1663101326220}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}